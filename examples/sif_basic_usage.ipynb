{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics.classification import accuracy_score\n",
    "\n",
    "from textvec import vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_imdb_data(base_dir, num_files=5000):\n",
    "    def get_df(corpus_type):\n",
    "        texts = []\n",
    "        y = []\n",
    "        corpus_type_dir = os.path.join(base_dir, f'{corpus_type}/pos/')\n",
    "        for i, f_name in enumerate(os.listdir(corpus_type_dir)):\n",
    "            if i == num_files: break\n",
    "            f_path = os.path.join(corpus_type_dir, f_name)\n",
    "            with open(f_path) as f:\n",
    "                texts.append(f.read())\n",
    "                y.append(1)\n",
    "        corpus_type_dir = os.path.join(base_dir, f'{corpus_type}/neg/')\n",
    "        for i, f_name in enumerate(os.listdir(corpus_type_dir)):\n",
    "            if i == num_files: break\n",
    "            f_path = os.path.join(corpus_type_dir, f_name)\n",
    "            with open(f_path) as f:\n",
    "                texts.append(f.read())\n",
    "                y.append(0)\n",
    "        df = pd.DataFrame()\n",
    "        df['y'] = y\n",
    "        df['text'] = texts\n",
    "        return df\n",
    "    train_data = shuffle(get_df('train'))\n",
    "    test_data = shuffle(get_df('test'))\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = get_binary_imdb_data(\"/home/enio/Загрузки/data/aclImdb\", num_files=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"[A-Za-z]\\w+\")\n",
    "train_tokenized = [tokenizer.tokenize(doc) for doc in train.text]\n",
    "test_tokenized = [tokenizer.tokenize(doc) for doc in test.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = KeyedVectors.load_word2vec_format(\n",
    "    \"/home/enio/ds/embeddings/word2vec/GoogleNews-vectors-negative300.bin.gz\", \n",
    "    binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All word vectors should be scaled to **l2 norm**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pipeline\n",
    "You can use `SifVectorizer` in the Pipeline like other vectorizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8032\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", vectorizers.SifVectorizer(embeddings, alpha=0.1, npc=1)),\n",
    "    (\"clf\", RandomForestClassifier(n_jobs=-1, n_estimators=600))\n",
    "])\n",
    "\n",
    "pipeline.fit(train_tokenized, train.y)\n",
    "preds = pipeline.predict(test_tokenized)\n",
    "accuracy = accuracy_score(test.y, preds)\n",
    "print(f\"test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced pipeline usage\n",
    "You can also create your own Tokenizer class to make working with the `Pipeline` class even more convenient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(TransformerMixin):\n",
    "    def __init__(self, token_pattern):\n",
    "        self.token_pattern = token_pattern\n",
    "        self.tokenizer = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.tokenizer = RegexpTokenizer(self.token_pattern)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [\n",
    "            self.tokenizer.tokenize(sent)\n",
    "            for sent in X\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8046\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"tokenizer\", Tokenizer(r\"[A-Za-z]\\w+\")),\n",
    "    (\"vectorizer\", vectorizers.SifVectorizer(embeddings, alpha=0.1, npc=1)),\n",
    "    (\"clf\", RandomForestClassifier(n_jobs=-1, n_estimators=600))\n",
    "])\n",
    "\n",
    "# note that here `fit` function takes\n",
    "# non-tokenized text\n",
    "pipeline.fit(train.text, train.y)\n",
    "preds = pipeline.predict(test.text)\n",
    "accuracy = accuracy_score(test.y, preds)\n",
    "print(f\"test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
